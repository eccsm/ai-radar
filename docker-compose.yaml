# docker-compose.yml - Working configuration for AI Radar
# Works with external vault created by ai-radar.ps1

# Base environment variables
x-env: &base-env
  PYTHONUNBUFFERED: "1"
  DB_HOST: db
  DB_PORT: 5432
  DB_USER: ai
  DB_PASSWORD: ai_pwd
  DB_NAME: ai_radar
  NATS_URL: nats://nats:4222
  MINIO_ENDPOINT: http://minio:9000
  MINIO_ACCESS_KEY: minio
  MINIO_SECRET_KEY: minio_pwd
  VAULT_ADDR: http://host.docker.internal:8200

# Base service configuration
x-service-base: &service-base
  restart: on-failure
  deploy:
    resources:
      limits:
        cpus: '0.5'
        memory: 512M
      reservations:
        cpus: '0.1'
        memory: 128M

services:
  # ─────────────────────────────────────────────────────────── CORE INFRASTRUCTURE ──
  db:
    <<: *service-base
    build:
      context: .
      dockerfile: Dockerfile.db
    environment:
      POSTGRES_DB: ai_radar
      POSTGRES_USER: ai
      POSTGRES_PASSWORD: ai_pwd
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    volumes:
      - pg_data:/var/lib/postgresql/data
    networks:
      - backplane

  nats:
    <<: *service-base
    image: nats:2.10.7-alpine
    command: -js -m 8222
    ports:
      - "4222:4222"
      - "8222:8222"
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    networks:
      - backplane
      - public

  minio:
    <<: *service-base
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio_pwd
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - backplane
      - public

  # MinIO bucket initialization
  toolhub:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: /bin/sh
    command: |
      -c "
      until (mc alias set minio http://minio:9000 minio minio_pwd) do echo 'Waiting for MinIO...' && sleep 1; done;
      mc mb minio/ai-radar-content --ignore-existing;
      mc mb minio/ai-radar-backups --ignore-existing;
      mc anonymous set download minio/ai-radar-content;
      echo 'MinIO buckets configured successfully';
      "
    networks:
      - backplane

  # ─────────────────────────────────────────────────────────── SCHEDULER ──
  scheduler:
    build:
      context: ./scheduler
      dockerfile: Dockerfile
    <<: *service-base
    environment:
      <<: *base-env
      API_BASE_URL: http://api:8000
      PYTHONPATH: /app
      FETCH_INTERVAL: "3600"  # 1 hour for production (was 1800/30min)
      STATS_INTERVAL: "3600"  # 1 hour by default
      ADMIN_USERNAME: admin
      ADMIN_PASSWORD: admin
      NATS_SUBJECT_PREFIX: ai-radar
      NATS_STREAM_NAME: ai-radar-tasks # Default stream name for tasks
    depends_on:
      db:
        condition: service_healthy
      nats:
        condition: service_healthy
    networks:
      - backplane
    profiles:
      - dev
      - prod

  # ─────────────────────────────────────────────────────────── AGENTS ───────────────
  fetcher:
    build:
      context: ./agents/fetcher
      dockerfile: Dockerfile
      target: production
    <<: *service-base
    environment:
      <<: *base-env
      PYTHONPATH: /app
    volumes:
      - ./_core:/app/_core:ro
    depends_on:
      db:
        condition: service_healthy
      nats:
        condition: service_healthy
      minio:
        condition: service_healthy
    networks:
      - backplane
    profiles:
      - dev
      - prod

  summariser:
    build:
      context: ./agents/summariser
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-development}
    <<: *service-base
    environment:
      <<: *base-env
      PYTHONPATH: /app

    depends_on:
      db:
        condition: service_healthy
      nats:
        condition: service_healthy
      minio:
        condition: service_healthy
    volumes:
      - ./_core:/app/_core:ro
      - ./agents/_core:/app/agents/_core:ro
      - ./agents/summariser/main.py:/app/main.py:ro
    networks:
      - backplane
      - public
    extra_hosts:
      - "host.docker.internal:host-gateway"
    profiles:
      - dev
      - prod

  ranker:
    build:
      context: ./agents/ranker
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-development}
    <<: *service-base
    environment:
      <<: *base-env
      PYTHONPATH: /app
    depends_on:
      db:
        condition: service_healthy
      nats:
        condition: service_healthy
    volumes:
      - ./_core:/app/_core:ro
      - ./agents/_core:/app/agents/_core:ro
      - ./agents/ranker/main.py:/app/main.py:ro
    networks:
      - backplane
    profiles:
      - dev
      - prod

  sharer:
    build:
      context: ./agents/sharer
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-development}
    <<: *service-base
    environment:
      <<: *base-env
      PYTHONPATH: /app
    depends_on:
      db:
        condition: service_healthy
      nats:
        condition: service_healthy
    volumes:
      - ./_core:/app/_core:ro
      - ./agents/_core:/app/agents/_core:ro
      - ./agents/sharer/main.py:/app/main.py:ro
    networks:
      - backplane
    profiles:
      - dev
      - prod

  # ─────────────────────────────────────────────────────────── USER INTERFACE ──
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    <<: *service-base
    ports:
      - "8000:8000"
    environment:
      <<: *base-env
      PYTHONPATH: /app:/app/parent
    depends_on:
      db:
        condition: service_healthy
      nats:
        condition: service_healthy
      minio:
        condition: service_healthy
    volumes:
      - ./_core:/app/_core:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - backplane
      - public
    extra_hosts:
      - "host.docker.internal:host-gateway"
    profiles:
      - dev
      - prod

  # Production UI (minimal version for base compose)
  ui:
    image: nginx:alpine
    <<: *service-base
    ports:
      - "3000:80"
    volumes:
      - ./ui-placeholder:/usr/share/nginx/html:ro
    networks:
      - public
    profiles:
      - prod

  # Development UI
  ui-dev:
    build:
      context: ./ai-radar-ui
      dockerfile: Dockerfile.dev
    <<: *service-base
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000/api
      - NODE_ENV=development
    volumes:
      - ./ai-radar-ui:/app:rw
      - /app/node_modules
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - public
    profiles:
      - dev

  # ─────────────────────────────────────────────────────────── DEVELOPMENT TOOLS ──
  pgadmin:
    image: dpage/pgadmin4:latest
    <<: *service-base
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_CHECK_EMAIL_DELIVERABILITY: "False"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      - db
    networks:
      - public
    profiles:
      - dev

  # ─────────────────────────────────────────────────────────── MONITORING ──
  prometheus:
    image: prom/prometheus:latest
    <<: *service-base
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    networks:
      - backplane
      - public
    profiles:
      - dev

  grafana:
    image: grafana/grafana:latest
    <<: *service-base
    ports:
      - "33000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - prometheus
      - loki
    networks:
      - public
    profiles:
      - dev

  loki:
    image: grafana/loki:3.0.0
    <<: *service-base
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki:/etc/loki
      - loki_data:/loki
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - backplane
      - public
    profiles:
      - dev

  promtail:
    image: grafana/promtail:3.0.0
    <<: *service-base
    volumes:
      - /var/log:/var/log
      - ./monitoring/promtail:/etc/promtail
    command: -config.file=/etc/promtail/config.yaml
    depends_on:
      loki:
        condition: service_healthy
    networks:
      - backplane
    profiles:
      - dev

  portainer:
    image: portainer/portainer-ce:latest
    <<: *service-base
    ports:
      - "9999:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    networks:
      - public
    profiles:
      - dev

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    <<: *service-base
    ports:
      - "8081:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    privileged: true
    networks:
      - public
    profiles:
      - dev

  nats-exporter:
    image: natsio/prometheus-nats-exporter:latest
    <<: *service-base
    command: 
      - "-varz"
      - "-connz"
      - "-subz"
      - "-routez"
      - "-jsz=all"
      - "-port=7777"
      - "http://nats:8222"
    ports:
      - "7777:7777"
    depends_on:
      nats:
        condition: service_healthy
    networks:
      - backplane
      - public
    profiles:
      - dev

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    <<: *service-base
    ports:
      - "9187:9187"
    environment:
      DATA_SOURCE_NAME: "postgresql://ai:ai_pwd@db:5432/ai_radar?sslmode=disable"
    depends_on:
      db:
        condition: service_healthy
    networks:
      - backplane
    profiles:
      - dev

# Networks
networks:
  backplane:
    internal: false
  public:

# Volumes
volumes:
  pg_data:
  minio_data:
  prometheus_data:
  grafana_data:
  portainer_data:
  pgadmin_data:
  loki_data: